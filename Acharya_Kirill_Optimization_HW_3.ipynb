{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a6fcbb6"
   },
   "source": [
    "# Домашнее задание 3\n",
    "\n",
    "Это домашнее задание по материалам второго семинаров. Дедлайн по отправке - 23:55 24 февраля. \n",
    "\n",
    "Домашнее задание выполняется в этом же Jupyter Notebook'e и присылается мне на почту: __beznosikov.an@phystech.edu__.\n",
    "\n",
    "Решение каждой задачи необходимо поместить после её условия.\n",
    "\n",
    "Файл должен называться: Фамилия_Имя_Optimization_HW_3\n",
    "\n",
    "При полном запуске Вашего решения (Kernel -> Restart & Run All) все ячейки должны выполняться без ошибок. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "969a8d32"
   },
   "source": [
    "## Задача 1\n",
    "\n",
    "Вновь рассмотрим задачу минимизации эмпирического риска:\n",
    "\\begin{equation}\n",
    "\\min_{w \\in \\mathbb{R}^d} \\frac{1}{n} \\sum\\limits_{i=1}^n l (g(w, x_i), y_i).\n",
    "\\end{equation}\n",
    "\n",
    "В прошлом задании работа шла с линейной модель $g(w, x) = w^T x$ и квадратичную функцию потерь $l(z, y) = (z-y)^2$. \n",
    "\n",
    "__(а)__ В дополнение к квадратичной функции потерь реализуйте логистическую/сигмоидную: $l(z,y) = \\ln (1 + \\exp(-yz))$ (__Важно: $y$ должен принимать значения $-1$ или $1$__). Выпишите градиент. Является ли новая задача регресии выпуклой? Оцените $L$ для новой функции потерь. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei_up59PzFgn"
   },
   "source": [
    "1) Gradient\n",
    "$$\\nabla_w Loss(w) = \\nabla_w \\frac1n \\sum\\limits_{i=1}^n \\ln(1 + \\exp(-w^Tx_i y_i)) = \\frac1n \\sum\\limits_{i=1}^n \\frac{-x_i y_i\\exp(-w^Tx_i y_i)}{1 + \\exp(-w^Tx_i y_i)}$$\n",
    "\n",
    "2) $L = \\| \\frac14 X_n^TX_n \\|$ as the reference from https://web.eecs.umich.edu/~fessler/course/598/l/n-03-gd.pdf page 53 \n",
    "\n",
    "3) Convexity: yes, the logistic regression is a convex optimization problem, because Logloss is a convex function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "COCwzZ5BygUN"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import my_optimization as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecdb57fe"
   },
   "source": [
    "__(б)__ Возьмите датасет _mushrooms_ из прошлого задания. Проделайте следующие шаги из прошлого задания, только с логистической функцией потерь:\n",
    "\n",
    "1) Разделите данные на две части: обучающую и тестовую.\n",
    "\n",
    "2) Для обучающей части $X_{train}$, $y_{train}$ оцените константу $L$ задачи обучения/оптимизации.\n",
    "\n",
    "3) Используя градиентный спуск, обучите новую модель (без ограничений и регуляризаций). Постройте график: точность от номера итерации.\n",
    "\n",
    "4) Если в пункте 3) пришлось столкнуться с проблемами или просто необходимо улучшить точность, то добавьте ограничения или $\\ell_2$-регуляризацию, как в прошлом ДЗ.\n",
    "\n",
    "5) Сравните с результатами квадратичной функции потерь из прошлого ДЗ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46b1db1d",
    "outputId": "311e0c8f-299b-4e4c-e436-76677be2e4a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 2.013288493062904\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "dataset = \"mushrooms.txt\" \n",
    "data = load_svmlight_file(dataset)\n",
    "X, y = data[0].toarray(), data[1]\n",
    "n, d = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=True)\n",
    "\n",
    "#2\n",
    "L = np.linalg.norm(1/(4*n) * X_train.T @ X_train)\n",
    "print(\"L =\", L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "19kyfBhM6YmS"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (682416,) (6093,112) (682416,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-cd94739a4c52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc_n_iter_dependency\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"basic\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-81233d39bb3e>\u001b[0m in \u001b[0;36macc_n_iter_dependency\u001b[1;34m(start, finish, step, GD_type, X_train, X_test, y_train, y_test, L, d, lambda_)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0macc_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinish\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mw_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGrad_Descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mw_true\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-81233d39bb3e>\u001b[0m in \u001b[0;36mGrad_Descent\u001b[1;34m(n_iter, X, lr, y, w_0, n)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mw_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGet_grad\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_old\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mw_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_old\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-81233d39bb3e>\u001b[0m in \u001b[0;36mGet_grad\u001b[1;34m(w, X, y, n)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mans\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mans\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (682416,) (6093,112) (682416,) "
     ]
    }
   ],
   "source": [
    "#3    \n",
    "acc_n_iter_dependency (1, 200, 5, \"basic\", X_train, X_test, y_train, y_test, L, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mo4Zq6Z5CkLv"
   },
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qu3yl8jVCF-O"
   },
   "outputs": [],
   "source": [
    "#5\n",
    "acc_hw_2 = 0.9960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81d96a89"
   },
   "source": [
    "## Задача 2\n",
    "\n",
    "__(a)__ Реализуйте метод тяжелого шарика. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00dd30eb"
   },
   "outputs": [],
   "source": [
    "def Momentum_Grad_Descent(n_iter, X, lr, gamma, y, w_0, n):\n",
    "    points = []\n",
    "    w_old = w_0\n",
    "    for i in range(n_iter):\n",
    "        grad = Get_grad (X, y, w_old, n)\n",
    "        if i < 2:\n",
    "            w_new = w_old - lr*grad \n",
    "        else:\n",
    "            w_new = w_old - lr*grad - gamma*(points[i] - points[i - 1])\n",
    "        w_old = w_new \n",
    "        points.append(w_old)\n",
    "    return points\n",
    "\n",
    "def Momentum_Draw_Graph (n_iter, X, lr, gamma, y, w_0, n, w_true, criteria): \n",
    "    points = Momentum_Grad_Descent(n_iter, X, lr, gamma, y, w_0, n)\n",
    "    diff_arr, crit_arr, x = [], [], []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        x.append(i + 1)\n",
    "        diff_arr.append(points[i] - w_true)\n",
    "        if criteria == \"x_criteria\":\n",
    "            crit_arr.append(np.linalg.norm(diff_arr[i]))\n",
    "        elif criteria == \"f_criteria\":\n",
    "            crit_arr.append(np.abs(Logloss(X, y, points[i], n) - Logloss(X, y, w_true, n)))\n",
    "\n",
    "    y = crit_arr\n",
    "    if criteria == \"x_criteria\":\n",
    "        plt.plot(x, y, label = \"||w^k - w*||\")\n",
    "    elif criteria == \"f_criteria\":\n",
    "        plt.plot(x, y, label = \"|f(w^k) - f(w*)|\")\n",
    "\n",
    "    plt.xlabel('n_iter')\n",
    "    plt.ylabel('criteria')\n",
    "    plt.title('Standard axis convergence')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fe201d2"
   },
   "source": [
    "__(б)__ Решите задачу логистической регрессии с помощью метода тяжелого шарика (не забудьте разделить выборку на две части: обучающую и тестовую). Зафиксируйте шаг $\\frac{1}{L}$ и перебирайте разные значения моментума от -1 до 1. Постройте график сходимости метода от числа итераций (критерий сходимости подберите самостоятельно) для различных значений моментума. Всегда ли сходимость является монотонной?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "d40582dc",
    "outputId": "a20032f1-c79e-492d-ac8d-217aff3064c8"
   },
   "outputs": [],
   "source": [
    "#ответ\n",
    "w_true = Grad_Descent(10**4, X_train, 1/L, y_train, np.ones(d), np.shape((X_train)[0])[-1] )\n",
    "for gamma in [-1, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "    Momentum_Draw_Graph (100, X, 1/L, y, np.ones(d), np.shape(X_train)[0])[-1], n, gamma, w_true, \"f_criteria\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3fb31fc"
   },
   "source": [
    "__(в)__ Для лучшего значения моментума постройте график зависимости точности модели на тестовой выборке от времени работы метода. Добавьте на этот же график сходимость градиентного спуска с шагом $\\frac{1}{L}$. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb9647ee"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "732f76c5"
   },
   "source": [
    "__(г)__ Если в пунктах (б) и (в) столкнулись с проблемами, попробуйте $\\ell_2$-регуляризовать задачу или рассмотреть ее на ограниченном множестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f88834f"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7712495"
   },
   "source": [
    "__(д)__ Реализуйте ускоренный метод Нестерова (в форме Нестерова, а не который доказывали на семинаре). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aedb6c27"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "919f78fc"
   },
   "source": [
    "__(е)__ Решите задачу логистической регресии с помощью метода Нестерова (не забудьте разделить выборку на две части: обучающую и тестовую). Зафиксируйте шаг $\\frac{1}{L}$ и перебирайте разные значения моментума от -1 до 1. Проверьте также значения моментума равные $\\frac{k}{k+3}$, $\\frac{k}{k+2}$, $\\frac{k}{k+1}$ ($k$ - номер итерации), а если решаете сильно выпуклую задачу, то и $\\frac{\\sqrt{L} - \\sqrt{\\mu}}{\\sqrt{L} + \\sqrt{\\mu}}$. Постройте график сходимости метода от числа итераций (критерий сходимости подберите самостоятельно) для различных значений моментума. Всегда ли сходимость является монотонной?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5fd3001"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e74034f6"
   },
   "source": [
    "__(ж)__ Для лучшего значения моментума постройте график зависимости точности модели на тестовой выборке от времени работы метода. Добавьте этот график к графикам для тяжелого шарика и градиентного спуска из пункта (г). Сделайте итоговый вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55bcfb5c"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56317873"
   },
   "source": [
    "__Бонусные пункт__\n",
    "\n",
    "__(з)__ Сделаем подбор константы $L$ адаптивным. Как упоминалось на семинаре, можно измерять локальную $L$, используя:\n",
    "$$\n",
    "f(y) \\leq f(x^k) + \\langle \\nabla f(x^k), y - x^k \\rangle + \\frac{L}{2}\\|x^k - y\\|_2^2\n",
    "$$\n",
    "В частности, может подойти процедура:\n",
    "\n",
    "```python\n",
    "def backtracking_L(f, grad, x, h, L0, rho):\n",
    "    L = L0\n",
    "    fx = f(x)\n",
    "    gradx = grad(x)\n",
    "    while True:\n",
    "        y = x - 1 / L * h\n",
    "        if f(y) <= fx - 1 / L gradx.dot(h) + 1 / (2 * L) h.dot(h):\n",
    "            break\n",
    "        else:\n",
    "            L = L * rho\n",
    "    return L\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f87c7ad"
   },
   "source": [
    "Каким стоит взять __h__? __rho__ должно быть больше или меньше 1? __L0__ надо брать заведомо большим или маленьким?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caad1f26"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cd9efb5"
   },
   "source": [
    "__(и)__ Поэксперементируйте с этой процедурой, встроенной в подбор $L$ для шага градиентного спуска. В качестве задачи продолжайте рассматривать логистическую регрессию из Задачи 1. Аналогично встройте процедуру подбора $L$ в метод тяжелого шарика и ускоренный метод Нестерова. Постройте график сходимости метода от числа итераций (критерий сходимости подберите самостоятельно). Отобразите на этом графике градиентный спуск, тяжелый шарик и метод Нестерова с адаптивным шагом и шагом $\\frac{1}{L}$ (всего 6 линий на графике). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06d0027d"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41d242c4"
   },
   "source": [
    "__(к)__ Постройте аналогичный пункту (и) график точности модели от времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3e880742"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5de0ffdd"
   },
   "source": [
    "__(л)__ В [работе](https://arxiv.org/pdf/1204.3982.pdf) представлена техника рестартов для подавления немонотонной сходимости Алгоритма 2 (метод Нестерова). Попробуйте повторить эксперименты авторов на $\\ell_2$-регуляризованной квадратичной или логистической регресии. Возьмите параметр регуляризации $\\lambda = L / 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ead8a333"
   },
   "outputs": [],
   "source": [
    "#ответ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
